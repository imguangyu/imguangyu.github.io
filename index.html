<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guangyu Sun</title>
  
  <meta name="author" content="Guangyu Sun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<style>
  table.imgtable, table.imgtable td{
    border: none;
    /* height: auto; */
    /* text-align: left; */
  }
</style>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Guangyu Sun</name>
              </p>
              <!-- <p style="font-size:15px"> -->
              <p> 
                I am a third-year Ph.D. student with <a href='https://www.crcv.ucf.edu/chenchen/'>Prof. Chen Chen</a> at the University of Central Florida. I earned my Master of Science of Computer Science at the University of Rochester, advised by <a href='https://www.cs.rochester.edu/~cxu22/'>Prof. Chenliang Xu</a>. Before my graduate education, I earned my Bachelor's Degree in Computer Science at the University of Missouri, advised by <a href='http://digbio.missouri.edu/'>Prof. Dong Xu</a>, and my Bachelor's Degree in Computer Science and Technology at Shandong University. My research interests include Federated Learning, Generative AI, Multi-modality Learning, and Efficient Fine-tuning.
              </p>
              <!-- <p> -->
                <!-- I have a broad interest in deep learning and computer vision. My current research mainly focuses on large model adaptation, efficient neural networks, runtime adaptive networks, representation learning and its applications on image and video understanding. -->
              <!-- </p> -->
              <!-- <p> My works have been selected as CVPR Best Paper Finalist (2022) and ICCV Oral Presentation (2023). </p> -->
              <p style="text-align:center">
                <a href="mailto:guangyu.sun@ucf.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=e4NjsVIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/imguangyu">Github</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/guangyu-sun-686b94198">LinkedIn</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo.jpg"><img style="width:100%;max-width:100%; border-radius: 50%; object-fit: cover; border: 2px solid #ccc;" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink" ></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
          </td>
          </tr>
          <tr>
            
          </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <ul style="width: auto; height: 150px; overflow: auto">
                <li> <b> [Oct. 2024]</b> Our paper <i>Exploring Parameter-Efficient Fine-Tuning to Enable Foundation Models in Federated Learning</i> has been accepted on <b>IEEE Big Data 2024</b>!</li>
                <li> <b> [Oct. 2024]</b> Our paper <i>Navigating Heterogeneity and Privacy in One-Shot Federated Learning with Diffusion Models</i> has been accepted on <b>WACV 2025</b>!</li>
                <li> <b> [Aug. 2024]</b> I started my Research Intern on Vision Foundation Model and Generative AI at <b>Sony AI</b>!</li>
                <li> <b> [July 2024]</b> Our paper <i>Towards Multi-modal Transformers in Federated Learning</i> has been accepted on <b>ECCV 2024</b>!</li>
                <li> <b> [Apr. 2024]</b> Our papers <i>Towards Multi-modal Transformers in Federated Learning</i> and <i>Navigating Heterogeneity and Privacy in One-Shot Federated Learning with Diffusion Models</i> are available on arXiv.</li>
                <li> <b> [Aug. 2023]</b> Our paper <i>FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning</i> is available on <a href='https://arxiv.org/pdf/2308.09160.pdf'>arXiv</a>.</li>
                
                <li> <b> [July 2023]</b> Our paper <i>FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning</i> has been accepted on <b>ICCV 2023</b>! Code and paper will be available soon.</li>
                
                <li> <b> [Nov. 2022]</b> Our paper <i>Conquering the Communication Constraints to Enable Large Pre-Trained Models in Federated Learning</i> is now available on <a href="https://arxiv.org/abs/2210.01708"> arXiv</a>. </li>
                
                <li> <b>[May 2022]</b> I've earned my Master of Science in Computer Science degree at the University of Rochester!</li> 
                
                <li> <b>[Mar. 2022]</b> I will join <a href="https://www.crcv.ucf.edu/chenchen/">Prof. Chen Chen's group</a> as a Ph.D. student in 2022 Fall!</li>
              </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Intern Experience</heading>
            </td>
          </tr>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/sony.png' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Research Intern on Vision Foundation Model and Generative AI</strong>
                <br> Sony AI America
                <br> <i>Remote. Aug. 2024 - Nov. 2024</i>
                <p></p>
                <p> Investigated enhancing vision foundation model adaptation with semi-supervised federated learning.</p>
              </td>
            </tr>
          </tr>
          </table>
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <table class='imgtable' style="border-collapse:collapse">
          <tr bgcolor="#ffffd0">
            <td align="center" style="width:200px">
            <a href="https://arxiv.org/abs/2404.12467">
            <img src="images/FedCola.png" alt=""  height="110px" style='width:200px;object-fit:contain;' />
              </a>
            </td>
            <td align="left">
              <p>
                <a href="https://arxiv.org/abs/2404.12467">
                <b>Towards Multi-modal Transformers in Federated Learning</b><br></a>
                <b>Guangyu Sun</b>, Matias Mendieta, Aritra Dutta, Xin Li, Chen Chen.<br>
                <i>2024 European Conference on Computer Vision. </i><b>ECCV 2024</b>.<br>
                [<a href="https://arxiv.org/abs/2404.12467">Paper</a>]
              </p>
            </td>
          </tr>
          <tr>
            <td align="center" style="width:200px">
            <a href="https://arxiv.org/abs/2405.01494">
            <img src="images/FedDiff.png" alt=""  height="110px" style='width:200px;object-fit:contain;padding-right:10px;' />
              </a>
            </td>
            <td align="left">
              <p>
                <a href="https://arxiv.org/abs/2405.01494">
                <b>Navigating Heterogeneity and Privacy in One-Shot Federated Learning with Diffusion Models</b><br></a>
                Matias Mendieta, <b>Guangyu Sun</b>, Chen Chen.<br>
                <i>2025 IEEE/CVF Winter Conference on Applications of Computer Vision.</i> <b>WACV 2025</b>.<br>
                [<a href="https://arxiv.org/abs/2405.01494">Paper</a>]
              </p>
            </td>
          </tr>
          <tr bgcolor="#ffffd0">
            <td align="center" style="width:200px">
              <a href="https://arxiv.org/abs/2308.09160"><img src="images/fedperfix.png" alt="FedPerfix" height="110px"  style='width:200px; object-fit:contain;'/></a>
            </td>
            <td align="left">
              <p>
                <a href="https://arxiv.org/abs/2308.09160"><b>FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning</b><br></a>
                <b>Guangyu Sun</b>, Matias Mendieta, Jun Luo, Shandong Wu, Chen Chen.<br>
                <i>2023 IEEE/CVF International Conference on Computer Vision. </i><b>ICCV 2023</b>.<br>
                [<a href='https://arxiv.org/abs/2308.09160'>Paper</a>][<a href='https://github.com/imguangyu/FedPerfix'>Code</a>]
              </p>
            </td>
          </tr>
          <tr>
            <td align="center" style="width:200px">
            <a href="https://arxiv.org/abs/2210.01708">
            <img src="images/FedPEFT.JPG" alt=""  height="110px" style='width:200px;object-fit:contain;' />
              </a>
            </td>
            <td align="left">
              <p>
                <a href="https://arxiv.org/abs/2210.01708">
                <b>Exploring Parameter-Efficient Fine-Tuning to Enable Foundation Models in Federated Learning</b><br></a>
                <b>Guangyu Sun</b>, Umar Khalid, Matias Mendieta, Pu Wang, Chen Chen.<br>
                <i>2024 IEEE International Conference on Big Data</i><br>
                [<a href="https://arxiv.org/abs/2210.01708">Paper</a>]
              </p>
            </td>
          </tr>
          <tr>
            <td align="center" style="width:200px">
             <a href="https://arxiv.org/abs/2112.06320">
              <img src="images/anomalycrossing.png" alt=""  height="110px" style='width:200px;object-fit:contain;' />
              </a>
            </td>
            <td align="left">
              <p>
                <a href="https://arxiv.org/abs/2112.06320">
                <b>Anomaly Crossing: New Horizons for Video Anomaly Detection as Cross-domain Few-shot Learning</b></a><br>
                <b>Guangyu Sun*</b>, Zhang Liu*, Lianggong Wen, Jing Shi, Chenliang Xu.<br>
                [<a href="https://arxiv.org/abs/2112.06320">Paper</a>]
                [<a href="https://github.com/imguangyu/AnomalyCrossing">Code</a>]
              </p>
            </td>
          </tr>
          <tr>
            <td align="center" style="width:200px">
              <a href="https://ieeexplore.ieee.org/document/9300285">
              <img src="images/electric.gif" alt="" height="110x p" style='width:200px;object-fit:contain;'/>
              </a>
            </td>
            <td align="left">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9300285">
                <b>Deep Learning Detection of Inaccurate Smart Electricity Meters: A Case Study</b></a><br>
                Ming Liu*, Dongpeng Liu*, <b>Guangyu Sun</b>, Yi Zhao, Duolin Wang, Fangxing Liu, Xiang Fang, Qing He, Dong Xu.<br>
                <i>IEEE Industrial Electronics Magazine</i><br>
                [<a href="https://ieeexplore.ieee.org/document/9300285">Paper</a>]
              </p>
            </td>
          </tr>
          <tr>
            <td align="center" style="width:200px">
             <a href="https://pubs.er.usgs.gov/publication/70243648">
              <img src="images/water.jpg" alt=""  height="110px" style='width:200px;object-fit:contain;'/></a>
            </td>
            <td align="left">
              <p>
                <a href="https://pubs.er.usgs.gov/publication/70243648">
                <b>Assessing Environmental Oil Spill Based on Fluorescence Images of Water Samples and Deep Learning</b> </a><br>
                Dongpeng Liu, Ming Liu, <b>Guangyu Sun</b>, Zhiqian Zhou, Duolin Wang, Fei He, Jiaxin Li, Ryan Gettler, Eric Brunson, Jeffery Steevens, Dong Xu.<br>
                <i>Journal of Environmental informatics</i><br>
                [<a href="https://pubs.er.usgs.gov/publication/70243648">Paper</a>]
              </p>
            </td>
          </tr>
        </table>
        
        <table style="width:40%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
        <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=YfaCwNsPNRQJWJCQS4AAf1MzKs32Z5Eni7Py_3TVFkk&cl=ffffff&w=a"></script>
      </td>
    </tr>
    </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

</body>

</html>
